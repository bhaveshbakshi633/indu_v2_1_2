#!/usr/bin/env python3
"""
Record test samples to diagnose AEC issues.

This will record TWO samples:
1. TTS only: Edge TTS playing through speakers (mic picks it up)
2. TTS + Human: Both Edge TTS and you speaking simultaneously

These recordings will help diagnose:
- Actual amplitude ranges
- How much echo the mic picks up
- Timing/synchronization issues
"""

import numpy as np
import sounddevice as sd
import soundfile as sf
import edge_tts
import asyncio
import os
from datetime import datetime

SAMPLE_RATE = 16000
OUTPUT_DIR = "test_recordings"

async def generate_tts(text: str, output_file: str):
    """Generate TTS audio file"""
    print(f"Generating TTS: '{text}'")
    communicate = edge_tts.Communicate(text, "en-US-AriaNeural")
    await communicate.save(output_file)
    print(f"Saved TTS to: {output_file}")

def record_audio(duration_seconds: float, filename: str):
    """Record audio from microphone"""
    print(f"\nüé§ Recording for {duration_seconds} seconds...")
    print("3...")
    import time
    time.sleep(1)
    print("2...")
    time.sleep(1)
    print("1...")
    time.sleep(1)
    print("üî¥ RECORDING NOW!")

    # Record
    recording = sd.rec(
        int(duration_seconds * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype='int16'
    )
    sd.wait()

    print("‚úÖ Recording complete!")

    # Save as WAV
    sf.write(filename, recording, SAMPLE_RATE)
    print(f"Saved recording to: {filename}")

    return recording

def play_audio(filename: str):
    """Play audio file"""
    data, sr = sf.read(filename)
    print(f"\nüîä Playing: {filename}")
    sd.play(data, sr)
    sd.wait()
    print("‚úÖ Playback complete!")

async def main():
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Test text (should be around 10 seconds when spoken)
    test_text = """Hello, this is a test of the acoustic echo cancellation system.
    I am speaking for approximately ten seconds to provide enough audio data for analysis.
    This recording will help us understand the amplitude ranges, timing synchronization,
    and how well the echo cancellation works in practice. The voice you are hearing is
    generated by Edge TTS, and we will compare it with microphone recordings."""

    # Generate TTS
    tts_file = f"{OUTPUT_DIR}/tts_{timestamp}.mp3"
    await generate_tts(test_text, tts_file)

    # Load TTS to check duration
    tts_data, tts_sr = sf.read(tts_file)
    tts_duration = len(tts_data) / tts_sr
    print(f"TTS duration: {tts_duration:.2f} seconds")

    # ============================================
    # TEST 1: Record TTS only (mic picks up echo)
    # ============================================
    print("\n" + "="*60)
    print("TEST 1: TTS ONLY (microphone picks up speakers)")
    print("="*60)
    print("Instructions:")
    print("- Stay SILENT during this recording")
    print("- Let the microphone pick up ONLY the TTS from speakers")
    print()
    input("Press Enter when ready to start Test 1...")

    # Start playing TTS in background and record simultaneously
    import threading

    def play_tts_delayed():
        import time
        time.sleep(0.5)  # Small delay to ensure recording starts first
        play_audio(tts_file)

    # Record for 10 seconds (or TTS duration + 1s, whichever is longer)
    record_duration = max(10.0, tts_duration + 1.0)

    print("\nStarting recording...")
    play_thread = threading.Thread(target=play_tts_delayed)
    play_thread.start()

    tts_only_recording = record_audio(record_duration, f"{OUTPUT_DIR}/mic_tts_only_{timestamp}.wav")
    play_thread.join()

    # ============================================
    # TEST 2: Record TTS + Human speech
    # ============================================
    print("\n" + "="*60)
    print("TEST 2: TTS + HUMAN (both speaking)")
    print("="*60)
    print("Instructions:")
    print("- SPEAK during this recording while TTS is playing")
    print("- Try to interrupt or talk over the TTS")
    print("- Say things like: 'Wait', 'Stop', 'Hello', etc.")
    print()
    input("Press Enter when ready to start Test 2...")

    print("\nStarting recording...")
    play_thread = threading.Thread(target=play_tts_delayed)
    play_thread.start()

    tts_human_recording = record_audio(record_duration, f"{OUTPUT_DIR}/mic_tts_human_{timestamp}.wav")
    play_thread.join()

    # ============================================
    # Analysis
    # ============================================
    print("\n" + "="*60)
    print("ANALYSIS")
    print("="*60)

    # Load TTS reference
    tts_ref, _ = sf.read(tts_file)
    # Resample to 16kHz if needed
    if tts_sr != SAMPLE_RATE:
        import scipy.signal
        tts_ref = scipy.signal.resample(tts_ref, int(len(tts_ref) * SAMPLE_RATE / tts_sr))
    # Convert stereo to mono if needed
    if len(tts_ref.shape) > 1:
        tts_ref = np.mean(tts_ref, axis=1)

    # Convert to float32
    tts_ref = tts_ref.astype(np.float32)

    print(f"\nTTS Reference Audio:")
    print(f"  Shape: {tts_ref.shape}")
    print(f"  Data type: {tts_ref.dtype}")
    print(f"  Range: [{tts_ref.min():.3f}, {tts_ref.max():.3f}]")
    print(f"  RMS Energy: {np.sqrt(np.mean(tts_ref ** 2)):.3f}")

    # Load mic recordings
    mic_tts_only = tts_only_recording.flatten().astype(np.float32)
    mic_tts_human = tts_human_recording.flatten().astype(np.float32)

    print(f"\nMicrophone Recording (TTS only):")
    print(f"  Shape: {mic_tts_only.shape}")
    print(f"  Data type: {mic_tts_only.dtype}")
    print(f"  Range: [{mic_tts_only.min():.1f}, {mic_tts_only.max():.1f}]")
    print(f"  RMS Energy: {np.sqrt(np.mean(mic_tts_only ** 2)):.1f}")

    print(f"\nMicrophone Recording (TTS + Human):")
    print(f"  Shape: {mic_tts_human.shape}")
    print(f"  Data type: {mic_tts_human.dtype}")
    print(f"  Range: [{mic_tts_human.min():.1f}, {mic_tts_human.max():.1f}]")
    print(f"  RMS Energy: {np.sqrt(np.mean(mic_tts_human ** 2)):.1f}")

    # Calculate amplitude scaling factor needed
    tts_rms = np.sqrt(np.mean(tts_ref ** 2))
    mic_tts_rms = np.sqrt(np.mean(mic_tts_only ** 2))

    if tts_rms > 0:
        scaling_factor = mic_tts_rms / tts_rms
        print(f"\n‚ö†Ô∏è  AMPLITUDE SCALING NEEDED:")
        print(f"  TTS needs to be multiplied by ~{scaling_factor:.1f} to match mic amplitude")

    # Test echo subtraction with different factors
    print(f"\n" + "="*60)
    print("TESTING ECHO SUBTRACTION")
    print("="*60)

    # Align lengths (use shorter length)
    test_len = min(len(tts_ref), len(mic_tts_only))
    tts_test = tts_ref[:test_len]
    mic_test = mic_tts_only[:test_len]

    suppression_factors = [0.5, 0.7, 0.8, 0.9, 1.0]

    print(f"\nOriginal mic RMS (with echo): {np.sqrt(np.mean(mic_test ** 2)):.1f}")
    print("\nTesting different suppression factors:")

    for factor in suppression_factors:
        # Scale TTS to match mic amplitude first
        tts_scaled = tts_test * scaling_factor

        # Subtract
        cleaned = mic_test - (tts_scaled * factor)
        cleaned_rms = np.sqrt(np.mean(cleaned ** 2))

        print(f"  Factor {factor:.1f}: Cleaned RMS = {cleaned_rms:.1f}")

    print(f"\n‚úÖ Test recordings saved to: {OUTPUT_DIR}/")
    print(f"Files created:")
    print(f"  - tts_{timestamp}.mp3 (TTS reference)")
    print(f"  - mic_tts_only_{timestamp}.wav (mic recording, TTS only)")
    print(f"  - mic_tts_human_{timestamp}.wav (mic recording, TTS + human)")

if __name__ == "__main__":
    asyncio.run(main())
