# NAAMIKA Brain v2.1 - Deployment Package

**Version**: 2.1
**Release Date**: 2026-01-13
**Description**: Production-ready NAAMIKA voice assistant with RAG (Retrieval Augmented Generation)

---

## ğŸ¯ What's Included

### Core System Files
- `server.py` - Main Flask server with WebSocket support
- `naamika_rag.py` - RAG engine with FAISS vector search
- `naamika_system_prompt.txt` - NAAMIKA personality and behavior rules
- `naamika_knowledge_base.txt` - SSi medical robotics knowledge base
- `config.json` - System configuration

### Frontend
- `templates/` - HTML templates (stream.html, config.html)
- `static/` - Static assets (CSS, JS, images)

### Audio
- `filler_audio/` - Pre-generated filler audio files

### Documentation
- `docs/README.md` - Original project documentation
- `docs/QUICKSTART.md` - Quick start guide
- `README_DEPLOYMENT.md` - This deployment guide

### Dependencies
- `requirements.txt` - Python package dependencies

---

## ğŸš€ Quick Deployment

### Prerequisites
- Python 3.10 or higher
- Ollama installed with `gemma2:2b` model
- 4GB+ RAM
- Ubuntu/Linux (recommended) or Windows/macOS

### Installation Steps

1. **Navigate to deployment folder**
```bash
cd naamika_brain_v2_1
```

2. **Create virtual environment**
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

4. **Install Ollama model**
```bash
ollama pull gemma2:2b
```

5. **Run setup script** (creates vectorstore)
```bash
python setup.py
```

6. **Start the server**
```bash
python server.py
```

7. **Access the interface**
Open browser: `http://localhost:5000`

---

## âš™ï¸ Configuration

### Edit `config.json` to customize:

```json
{
  "stt_backend": "google",           // STT: google, whisper_server, whisper
  "tts_backend": "edge",             // TTS: edge, piper
  "ollama_model": "gemma2:2b",       // LLM model
  "ollama_base_url": "http://localhost:11434",
  "enable_rag": true,                // Enable/disable RAG
  "vad_threshold": 0.5,              // Voice activity detection sensitivity
  "silence_duration": 0.5,           // Silence before stopping recording (seconds)
  "interrupt_cooldown": 1.5          // Time before allowing interrupts (seconds)
}
```

---

## ğŸ“‹ System Requirements

### Minimum Specs
- CPU: 4 cores
- RAM: 4GB
- Storage: 10GB free
- Network: Internet connection for Google STT & Edge TTS

### Recommended Specs
- CPU: 8+ cores
- RAM: 8GB+
- Storage: 20GB+ SSD
- GPU: Optional (for Whisper STT)

---

## ğŸ”§ Updating Knowledge Base

### To update NAAMIKA's knowledge:

1. **Edit knowledge base**
```bash
nano naamika_knowledge_base.txt
```

2. **Rebuild vectorstore**
```bash
rm -rf naamika_vectorstore
python setup.py
```

3. **Restart server**
```bash
python server.py
```

---

## ğŸ› Troubleshooting

### Issue: "No module named 'naamika_rag'"
**Solution**: Make sure you're in the correct directory and venv is activated

### Issue: "Ollama connection refused"
**Solution**: Start Ollama service
```bash
ollama serve
```

### Issue: "Empty responses from NAAMIKA"
**Solution**: Check vectorstore exists
```bash
python setup.py  # Rebuilds vectorstore
```

### Issue: "STT not working"
**Solution**: Check microphone permissions and config.json STT backend

---

## ğŸ“ File Structure

```
naamika_brain_v2_1/
â”œâ”€â”€ server.py                      # Main server
â”œâ”€â”€ naamika_rag.py                    # RAG engine
â”œâ”€â”€ naamika_system_prompt.txt         # NAAMIKA personality
â”œâ”€â”€ naamika_knowledge_base.txt        # Knowledge base
â”œâ”€â”€ config.json                    # Configuration
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ setup.py                       # Setup script
â”œâ”€â”€ README_DEPLOYMENT.md           # This file
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ stream.html               # Voice interface
â”‚   â””â”€â”€ config.html               # Config interface
â”œâ”€â”€ static/
â”‚   â””â”€â”€ [CSS, JS, images]
â”œâ”€â”€ filler_audio/
â”‚   â””â”€â”€ [Audio files]
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ QUICKSTART.md
â””â”€â”€ naamika_vectorstore/             # Created on first run
    â””â”€â”€ [FAISS index files]
```

---

## ğŸ” Security Notes

1. **API Keys**: Store Google STT credentials securely
2. **Network**: Use HTTPS in production (not HTTP)
3. **Firewall**: Restrict access to port 5000
4. **Updates**: Keep dependencies updated regularly

---

## ğŸ“Š Performance Optimization

### For Better Performance:
1. Use local Whisper STT instead of Google API
2. Enable GPU acceleration for Whisper
3. Use faster Ollama models (gemma2:2b is optimized for speed)
4. Increase `chunk_size` in naamika_rag.py for faster retrieval
5. Use SSD storage for vectorstore

---

## ğŸ¤ Voice Interaction Flow

```
User Speaks â†’ VAD Detects â†’ STT Transcribes â†’ RAG Retrieves Context
    â†“
LLM Generates Response â†’ TTS Synthesizes â†’ Audio Playback
    â†“
User Can Interrupt Anytime (Interrupt Detection Active)
```

---

## ğŸ“ Support

For issues, refer to:
- `docs/README.md` - Detailed documentation
- `docs/QUICKSTART.md` - Quick start guide
- GitHub Issues (if applicable)

---

## ğŸ”„ Version History

### v2.1 (2026-01-13)
- Fixed conversation loop issues
- Added surgery workflow knowledge
- Improved NAAMIKA identity distinction
- Added founder credit information
- Removed word count constraints
- Enhanced conversation flow handling

---

## ğŸ“ License

[Add your license information here]

---

## ğŸ™ Credits

Developed for SSi (SS Innovations)
Knowledge base based on SSi Mantra surgical robotic system documentation
